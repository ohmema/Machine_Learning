# 1.监督学习

* 回归
* 分类


# 2.无监督学习


* 无监督学习中没有任何的标签或者是有相同的标签或者就是没标签

* 无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法


![](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/images/94f0b1d26de3923fc4ae934ec05c66ab.png)


# 单边量线性回归

## 1.模型

## 2.cost-function

![](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/images/10ba90df2ada721cf1850ab668204dc9.png)



#### 图像理解 
![](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/images/0b789788fc15889fe33fb44818c40852.png)


* 找到合适的参数，使得最小，即达到中心点
![](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/images/86c827fe0978ebdd608505cd45feb774.png)

## 梯度下降

* 直观表现---起始点不同，得到的最低点不一样

![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E8%A1%A8%E7%A4%BA.jpg)

* 参数同时更新


![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95_%E5%90%8C%E6%97%B6%E6%9B%B4%E6%96%B0.png)


* 学习效率选取过大，导致结果发散

！[](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E5%AD%A6%E4%B9%A0%E6%95%88%E7%8E%87%E5%A4%A7_%E5%8F%91%E6%95%A3.jpg)


* 学习效率固定，下降速度也在逐渐减小


![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BA%8C%E7%BB%B4%E8%BF%87%E7%A8%8B.png)



## 梯度下降的线性回归


* 求解代价函数导数

![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.jpg)


* 注意同时更新


![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/ML-AndrewNg/Images/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95_%E5%90%8C%E6%97%B6%E6%9B%B4%E6%96%B0.png)

* 批量梯度下降

> 在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有m个训练样本求和












# 参考

* https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/blob/master/markdown/week1.md
* https://blog.csdn.net/abcjennifer/article/details/7691571
