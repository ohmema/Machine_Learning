# 模型评估

* 训练误差 ： 可以判断给定的问题是否容易学习，但是本质上不重要
* 测试误差 ： 反应了学习方法对未知的**测试数据集的预测能力**--泛化能力


# 模型选择
* 如果在假设空间存在真模型，所选模型要与真模型的参数个数相同，参数向量相近。
* 一味的提高对训练集的预测能力，所选模型的复杂度会比真的模型高---**过拟合**
* 避免过拟合 + 提高预测能力

> 过拟合 ： 学习时选择的模型参数包含过多，对已知数据预测的很好，未知数据预测很差

-------------
------------


# 模型选择方法

## 1 正则化（regularization）
> 正则化项一般是模型复杂度的单调递增函数，例如：模型参数向量的[范数](https://www.zybuluo.com/zzzxxxyyy/note/1211824)
>>> 范数： 向量 x 的范数衡量从原点到点 x 的距离
>>>> 常用L2范数 即欧几里得范数，---欧几里得距离

#### 1 一般形式
![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/Statical_Learning/Chapter_1-Generalization/Picture_used/%E7%BB%93%E6%9E%84%E9%A3%8E%E9%99%A9%E5%AE%9A%E4%B9%89.png)

**其中J(f)为正则化项**

#### 2. 不同形式
![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/Statical_Learning/Chapter_1-Generalization/Picture_used/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9%E5%BD%A2%E5%BC%8F.png)


#### 3. 理解
* 正则化的作用： 选择经验风险与模型复杂度同时较小的模型
* 复合 奥卡姆剃刀原理
> 能够很好解释，并且十分的简单的模型才是最好的模型

* 贝叶斯估计
> 正则化项对应于模型的先验概

* 复杂的模型有较大的先验概率，反之亦然。

-------------
-----------------

## 2 交叉验证（cross validation）
**基本思想：重复的使用数据**

#### 1 简单交叉验证
* 随机将数据分为两部分： 训练集+测试集
* 训练集在各种条件下训练模型----得到不同的模型，
* 测试集评价各个模型的测试误差，选出最小的

#### 2 s折交叉验证
* 随机的将数据切分为S个互不相交的大小相同的子集
* S-1个子集进行训练模型，剩下的子集测试模型
* 过程对可能的S种选择重复进行，选出误差最小的

#### 3 留一个数据交叉验证------数据缺乏
S=N










