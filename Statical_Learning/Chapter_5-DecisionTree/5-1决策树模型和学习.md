# 1 决策树模型

* 内部结点 ： 表示一个特征或者属性
* 叶结点： 表示一个类

![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/Statical_Learning/Chapter_5-DecisionTree/%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B.png)

# 2 决策树和条件概率分布

* 决策树所表示的条件概率分布由各个单元给定条件下的条件概率分布组成

![](https://github.com/LiuChuang0059/Machine_Learning/blob/master/Statical_Learning/Chapter_5-DecisionTree/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AF%B9%E5%BA%94%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.png)


# 3 决策树学习

* 根据给定的训练数据集构建一个决策树模型，对实例进行正确的分类

## 决策学习算法——————递归的选择最优特征

* 1. 构建根结点，将所有的训练书籍都存放在根节点
* 2. 选择一个最优特征，按照特征将训练数据集分割成子集，使得每个自己有一个当前条件下最好的分类。
* 3. 可以基本分类，构建叶结点，子集分到对应的叶结点上； 
* 4. 不能正确分类，子集选择新的最优特征

## 更好的泛化能力---- 自下而上剪枝

* 去掉过于细分的叶结点，使其退回到父结点，然后将父结点或更高的结点  改为新叶结点


## 决策树的生成对应于模型的局部选择，决策树的剪枝则考虑全局最优
